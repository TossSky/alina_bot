# app/llm_client.py
from __future__ import annotations
import asyncio
import os
from typing import List, Dict, Optional
import random

import httpx

from .config import settings
from .prompts import REFUSAL_STYLE, HUMANITY_HINTS

# –ë–∞–∑–æ–≤—ã–µ –¥–µ—Ñ–æ–ª—Ç—ã
DEFAULT_TEMPERATURE = 0.92  # –ü–æ–≤—ã—Å–∏–º –¥–ª—è –±–æ–ª–µ–µ –∂–∏–≤—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
DEFAULT_MAX_TOKENS = 400    # –£–º–µ–Ω—å—à–∏–º –¥–ª—è –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤

# –ü—Ä–æ—Ñ–∏–ª–∏ –ø–æ–¥ –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞
VERBOSITY_PROFILES = {
    "short":  {"max_tokens": 150, "temperature": 0.95},  # –û—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ, –∂–∏–≤—ã–µ
    "normal": {"max_tokens": 300, "temperature": 0.92},  # –£–º–µ—Ä–µ–Ω–Ω—ã–µ
    "long":   {"max_tokens": 450, "temperature": 0.90},  # –ß—É—Ç—å –¥–ª–∏–Ω–Ω–µ–µ
}

# –§—Ä–∞–∑—ã –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —á–µ–ª–æ–≤–µ—á–Ω–æ—Å—Ç–∏
HUMAN_TOUCHES = {
    "thinking": ["—Ö–º", "–Ω—É", "—ç–º", "–≤–æ—Ç", "–∫—Å—Ç–∞—Ç–∏"],
    "uncertainty": ["–Ω–∞–≤–µ—Ä–Ω–æ–µ", "–º–æ–∂–µ—Ç", "–≤—Ä–æ–¥–µ", "–∫–∞–∂–µ—Ç—Å—è", "–ø–æ—Ö–æ–¥—É"],
    "endings": [")", "...", "üåø", "üíõ", ""],
}

def _pick_profile(verbosity: Optional[str]) -> Dict[str, float]:
    if not verbosity:
        return {"max_tokens": DEFAULT_MAX_TOKENS, "temperature": DEFAULT_TEMPERATURE}
    verbosity = verbosity.lower().strip()
    return VERBOSITY_PROFILES.get(verbosity, {"max_tokens": DEFAULT_MAX_TOKENS, "temperature": DEFAULT_TEMPERATURE})

def _humanize_text(text: str) -> str:
    """–î–æ–±–∞–≤–ª—è–µ—Ç —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–µ —à—Ç—Ä–∏—Ö–∏ –∫ —Ç–µ–∫—Å—Ç—É"""
    if not text:
        return text
    
    # –ò–Ω–æ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º –≤–≤–æ–¥–Ω—ã–µ —Å–ª–æ–≤–∞
    if random.random() < 0.3:
        intro = random.choice(HUMAN_TOUCHES["thinking"])
        text = f"{intro}, {text[0].lower()}{text[1:]}"
    
    # –ò–Ω–æ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    if random.random() < 0.2:
        uncertainty = random.choice(HUMAN_TOUCHES["uncertainty"])
        # –í—Å—Ç–∞–≤–ª—è–µ–º –≤ —Å–ª—É—á–∞–π–Ω–æ–µ –º–µ—Å—Ç–æ
        words = text.split()
        if len(words) > 3:
            pos = random.randint(1, len(words) - 2)
            words.insert(pos, uncertainty)
            text = " ".join(words)
    
    # –ò–Ω–æ–≥–¥–∞ –¥–µ–ª–∞–µ–º "–æ–ø–µ—á–∞—Ç–∫—É" (–æ—á–µ–Ω—å —Ä–µ–¥–∫–æ)
    if random.random() < 0.05:
        text = _add_typo(text)
    
    return text

def _add_typo(text: str) -> str:
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—É—é –æ–ø–µ—á–∞—Ç–∫—É"""
    typos = [
        ("—á—Ç–æ", "—á—Ç"),
        ("—Å–µ–π—á–∞—Å", "—Å—á–∞—Å"),
        ("–º–æ–∂–µ—Ç", "–º–∂–µ—Ç"),
        ("–ø—Ä–∏–≤–µ—Ç", "–ø—Ä–≤–µ—Ç"),
        ("—Å–ø–∞—Å–∏–±–æ", "—Å–ø—Å–∏–±–æ"),
    ]
    for correct, typo in typos:
        if correct in text.lower():
            # –ó–∞–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ
            text = text.replace(correct, typo, 1)
            break
    return text

def _postprocess(text: str) -> str:
    """–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞"""
    if not text:
        return text
    
    # –£–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —è–≤–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã
    t = text.strip()
    for prefix in ("–ê–ª–∏–Ω–∞:", "–ê–ª–∏–Ω–∞ ‚Äî", "–ê–ª–∏–Ω–∞ -"):
        if t.startswith(prefix):
            t = t[len(prefix):].strip()
            break
    
    # –î–æ–±–∞–≤–ª—è–µ–º —á–µ–ª–æ–≤–µ—á–Ω–æ—Å—Ç–∏
    t = _humanize_text(t)
    
    return t.strip()

class LLMClient:
    """
    –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –∫ LLM-–ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º.
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö, –∂–∏–≤—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤.
    """

    def __init__(self):
        self.provider = (os.getenv("LLM_PROVIDER") or getattr(settings, "llm_provider", "deepseek")).lower()
        self.deepseek_api_key = os.getenv("DEEPSEEK_API_KEY") or getattr(settings, "deepseek_api_key", None)
        self.deepseek_model = getattr(settings, "deepseek_model", "deepseek-reasoner")
        self.openrouter_api_key = os.getenv("OPENROUTER_API_KEY") or getattr(settings, "openrouter_api_key", None)
        self.openrouter_model = getattr(settings, "openrouter_model", "openrouter/auto")
        self.ollama_host = getattr(settings, "ollama_host", "http://127.0.0.1:11434")
        self.ollama_model = getattr(settings, "ollama_model", "qwen2.5")
        
        self._client: Optional[httpx.AsyncClient] = None

    async def _get_client(self) -> httpx.AsyncClient:
        if self._client is None:
            # –£–º–µ–Ω—å—à–µ–Ω–Ω—ã–µ —Ç–∞–π–º–∞—É—Ç—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            self._client = httpx.AsyncClient(timeout=httpx.Timeout(15.0, connect=5.0))
        return self._client

    async def chat(
        self,
        messages: List[Dict[str, str]],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        *,
        verbosity: Optional[str] = None,
        safety: bool = False,
    ) -> str:
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.
        –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –∂–∏–≤—ã—Ö, —á–µ–ª–æ–≤–µ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤.
        """
        # –ø—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Ñ–∏–ª—å –¥–ª–∏–Ω—ã
        prof = _pick_profile(verbosity)
        temperature = float(temperature if temperature is not None else prof["temperature"])
        max_tokens = int(max_tokens if max_tokens is not None else prof["max_tokens"])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥—Å–∫–∞–∑–∫–∏ –¥–ª—è —á–µ–ª–æ–≤–µ—á–Ω–æ—Å—Ç–∏
        if random.random() < 0.3:  # –í 30% —Å–ª—É—á–∞–µ–≤
            hint = random.choice(list(HUMANITY_HINTS.values()))
            messages = messages + [{"role": "system", "content": hint}]
        
        # safety —Ä–µ–∂–∏–º
        if safety:
            messages = [{"role": "system", "content": REFUSAL_STYLE}] + messages
        
        prov = self.provider
        if prov == "deepseek":
            return await self._chat_deepseek(messages, temperature, max_tokens)
        elif prov == "openrouter":
            return await self._chat_openrouter(messages, temperature, max_tokens)
        elif prov == "ollama":
            return await self._chat_ollama(messages, temperature, max_tokens)
        else:
            return await self._chat_deepseek(messages, temperature, max_tokens)

    async def _chat_deepseek(
        self,
        messages: List[Dict[str, str]],
        temperature: float,
        max_tokens: int,
    ) -> str:
        if not self.deepseek_api_key:
            raise RuntimeError("DEEPSEEK_API_KEY –Ω–µ –∑–∞–¥–∞–Ω")

        url = "https://api.deepseek.com/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.deepseek_api_key}",
            "Content-Type": "application/json",
        }
        payload = {
            "model": self.deepseek_model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "top_p": 0.95,  # –î–æ–±–∞–≤–∏–º –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
            "frequency_penalty": 0.3,  # –£–º–µ–Ω—å—à–∞–µ–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
        }

        client = await self._get_client()
        try:
            resp = await client.post(url, headers=headers, json=payload)
            resp.raise_for_status()
            data = resp.json()
            txt = data["choices"][0]["message"]["content"]
            return _postprocess(txt)
        except Exception as e:
            # –ë—ã—Å—Ç—Ä—ã–π —Ñ–æ–ª–ª–±–µ–∫
            return "–æ–π, —á—Ç–æ-—Ç–æ —Å–≤—è–∑—å –±–∞—Ä–∞—Ö–ª–∏—Ç... –ø–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑?"

    async def _chat_openrouter(
        self,
        messages: List[Dict[str, str]],
        temperature: float,
        max_tokens: int,
    ) -> str:
        if not self.openrouter_api_key:
            raise RuntimeError("OPENROUTER_API_KEY –Ω–µ –∑–∞–¥–∞–Ω")
        url = "https://openrouter.ai/api/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.openrouter_api_key}",
            "Content-Type": "application/json",
        }
        payload = {
            "model": self.openrouter_model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "top_p": 0.95,
            "frequency_penalty": 0.3,
        }
        client = await self._get_client()
        try:
            resp = await client.post(url, headers=headers, json=payload)
            resp.raise_for_status()
            data = resp.json()
            txt = data["choices"][0]["message"]["content"]
            return _postprocess(txt)
        except Exception:
            return "—á—Ç–æ-—Ç–æ —Å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–æ–º... –¥–∞–≤–∞–π –ø–æ–ø–æ–∑–∂–µ?"

    async def _chat_ollama(
        self,
        messages: List[Dict[str, str]],
        temperature: float,
        max_tokens: int,
    ) -> str:
        url = f"{self.ollama_host.rstrip('/')}/api/chat"
        payload = {
            "model": self.ollama_model,
            "messages": messages,
            "options": {
                "temperature": float(temperature),
                "num_predict": int(max_tokens),
                "top_p": 0.95,
            },
            "stream": False,
        }
        client = await self._get_client()
        try:
            resp = await client.post(url, json=payload)
            resp.raise_for_status()
            data = resp.json()
            if "message" in data and "content" in data["message"]:
                return _postprocess(data["message"]["content"])
            if "messages" in data and data["messages"]:
                return _postprocess(data["messages"][-1].get("content", ""))
            return "—Ö–º, —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫..."
        except Exception:
            return "–Ω–µ –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å —Å–µ–π—á–∞—Å... –ø–æ–ø—Ä–æ–±—É–π —á—É—Ç—å –ø–æ–∑–∂–µ?"

    async def aclose(self):
        if self._client is not None:
            await self._client.aclose()
            self._client = None