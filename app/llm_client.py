# app/llm_client.py
from __future__ import annotations
import asyncio
import os
from typing import List, Dict, Optional
import random
import re

import httpx

from .config import settings
from .prompts import REFUSAL_STYLE, HUMANITY_HINTS

# –ë–∞–∑–æ–≤—ã–µ –¥–µ—Ñ–æ–ª—Ç—ã
DEFAULT_TEMPERATURE = 0.92
DEFAULT_MAX_TOKENS = 400

# –§—Ä–∞–∑—ã –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —á–µ–ª–æ–≤–µ—á–Ω–æ—Å—Ç–∏
HUMAN_TOUCHES = {
    "thinking": ["—Ö–º", "–Ω—É", "—ç–º", "–≤–æ—Ç", "–∫—Å—Ç–∞—Ç–∏"],
    "uncertainty": ["–Ω–∞–≤–µ—Ä–Ω–æ–µ", "–º–æ–∂–µ—Ç", "–≤—Ä–æ–¥–µ", "–∫–∞–∂–µ—Ç—Å—è", "–ø–æ—Ö–æ–¥—É"],
    "endings": [")", "...", "üåø", "üíõ", ""],
}

def _humanize_text(text: str) -> str:
    """–î–æ–±–∞–≤–ª—è–µ—Ç —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–µ —à—Ç—Ä–∏—Ö–∏ –∫ —Ç–µ–∫—Å—Ç—É"""
    if not text:
        return text
    
    # –ò–Ω–æ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º –≤–≤–æ–¥–Ω—ã–µ —Å–ª–æ–≤–∞
    if random.random() < 0.3:
        intro = random.choice(HUMAN_TOUCHES["thinking"])
        text = f"{intro}, {text[0].lower()}{text[1:]}"
    
    # –ò–Ω–æ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    if random.random() < 0.2:
        uncertainty = random.choice(HUMAN_TOUCHES["uncertainty"])
        words = text.split()
        if len(words) > 3:
            pos = random.randint(1, len(words) - 2)
            words.insert(pos, uncertainty)
            text = " ".join(words)
    
    # –ò–Ω–æ–≥–¥–∞ –¥–µ–ª–∞–µ–º "–æ–ø–µ—á–∞—Ç–∫—É" (–æ—á–µ–Ω—å —Ä–µ–¥–∫–æ)
    if random.random() < 0.05:
        text = _add_typo(text)
    
    return text

def _add_typo(text: str) -> str:
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—É—é –æ–ø–µ—á–∞—Ç–∫—É"""
    typos = [
        ("—á—Ç–æ", "—á—Ç"),
        ("—Å–µ–π—á–∞—Å", "—Å—á–∞—Å"),  
        ("–º–æ–∂–µ—Ç", "–º–∂–µ—Ç"),
        ("–ø—Ä–∏–≤–µ—Ç", "–ø—Ä–≤–µ—Ç"),
        ("—Å–ø–∞—Å–∏–±–æ", "—Å–ø—Å–∏–±–æ"),
    ]
    for correct, typo in typos:
        if correct in text.lower():
            text = text.replace(correct, typo, 1)
            break
    return text

def _format_lists(text: str) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ —Å—Ç—Ä–æ–∫"""
    if not text:
        return text
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤
    # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤–∏–¥–∞ "1. —Ç–µ–∫—Å—Ç 2. —Ç–µ–∫—Å—Ç" –∏–ª–∏ "1) —Ç–µ–∫—Å—Ç 2) —Ç–µ–∫—Å—Ç"
    patterns = [
        (r'(\d+)\.\s+([^.!?]+?)(?=\s*\d+\.|$)', r'\1. \2'),
        (r'(\d+)\)\s+([^.!?]+?)(?=\s*\d+\)|$)', r'\1) \2'),
    ]
    
    for pattern, replacement in patterns:
        matches = list(re.finditer(pattern, text))
        if matches:
            # –°–æ–±–∏—Ä–∞–µ–º –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏
            parts = []
            last_end = 0
            
            for match in matches:
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –¥–æ —Å–ø–∏—Å–∫–∞
                if match.start() > last_end:
                    parts.append(text[last_end:match.start()].rstrip())
                
                # –î–æ–±–∞–≤–ª—è–µ–º —ç–ª–µ–º–µ–Ω—Ç —Å–ø–∏—Å–∫–∞ —Å –ø–µ—Ä–µ–Ω–æ—Å–æ–º
                item = match.group(1) + '. ' + match.group(2).strip()
                parts.append('\n' + item)
                last_end = match.end()
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞—Ç–æ–∫ —Ç–µ–∫—Å—Ç–∞
            if last_end < len(text):
                remaining = text[last_end:].lstrip()
                if remaining:
                    parts.append('\n' + remaining)
            
            text = ''.join(parts).strip()
            break
    
    # –¢–∞–∫–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ (- –∏–ª–∏ ‚Ä¢)
    text = re.sub(r'(?:^|\s)[-‚Ä¢]\s+', '\n‚Ä¢ ', text)
    
    return text

def _postprocess(text: str) -> str:
    """–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞"""
    if not text:
        return text

    # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å—ã
    t = text.strip()
    for prefix in ("–ê–ª–∏–Ω–∞:", "–ê–ª–∏–Ω–∞ ‚Äî", "–ê–ª–∏–Ω–∞ -"):
        if t.startswith(prefix):
            t = t[len(prefix):].strip()
            break

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–ø–∏—Å–∫–∏
    t = _format_lists(t)
    
    # –î–æ–±–∞–≤–ª—è–µ–º —á–µ–ª–æ–≤–µ—á–Ω–æ—Å—Ç–∏
    t = _humanize_text(t)

    # –ó–∞–º–µ–Ω—è–µ–º Markdown –¥–ª—è Telegram
    t = re.sub(r'\*\*(.*?)\*\*', r'*\1*', t)
    
    # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
    t = re.sub(r'\n{3,}', '\n\n', t)

    return t.strip()

class LLMClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å DeepSeek API"""

    def __init__(self):
        self.api_key = os.getenv("DEEPSEEK_API_KEY") or getattr(settings, "deepseek_api_key", None)
        self.model = getattr(settings, "deepseek_model", "deepseek-chat")
        self._client: Optional[httpx.AsyncClient] = None

        if not self.api_key:
            raise RuntimeError("DEEPSEEK_API_KEY –Ω–µ –∑–∞–¥–∞–Ω –≤ .env —Ñ–∞–π–ª–µ")

    async def _get_client(self) -> httpx.AsyncClient:
        if self._client is None:
            self._client = httpx.AsyncClient(timeout=httpx.Timeout(15.0, connect=5.0))
        return self._client

    async def chat(
        self,
        messages: List[Dict[str, str]],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        *,
        verbosity: Optional[str] = None,  # –û—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        safety: bool = False,
    ) -> str:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ DeepSeek API"""
        
        temperature = float(temperature if temperature is not None else DEFAULT_TEMPERATURE)
        if verbosity == "short":
            max_tokens = 150
        else:
            max_tokens = int(max_tokens if max_tokens is not None else DEFAULT_MAX_TOKENS)

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥—Å–∫–∞–∑–∫–∏ –¥–ª—è —á–µ–ª–æ–≤–µ—á–Ω–æ—Å—Ç–∏
        if random.random() < 0.3:
            hint = random.choice(list(HUMANITY_HINTS.values()))
            messages = messages + [{"role": "system", "content": hint}]

        if safety:
            messages = [{"role": "system", "content": REFUSAL_STYLE}] + messages

        # –î–æ–±–∞–≤–ª—è–µ–º —è–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ –ø—Ä–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ø–∏—Å–∫–æ–≤
        messages.append({
            "role": "system", 
            "content": "–í–ê–ñ–ù–û: –ï—Å–ª–∏ –ø–∏—à–µ—à—å —Å–ø–∏—Å–æ–∫, –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–µ–ª–∞–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –ø—É–Ω–∫—Ç–∞!"
        })

        url = "https://api.deepseek.com/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }
        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "top_p": 0.95,
            "frequency_penalty": 0.3,
        }

        client = await self._get_client()
        try:
            resp = await client.post(url, headers=headers, json=payload)
            resp.raise_for_status()
            data = resp.json()
            txt = data["choices"][0]["message"]["content"]
            return _postprocess(txt)
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 401:
                return "–æ–π, –ø—Ä–æ–±–ª–µ–º—ã —Å –∫–ª—é—á–æ–º API... –ø—Ä–æ–≤–µ—Ä—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"
            elif e.response.status_code == 429:
                return "—Å–µ–∫—É–Ω–¥—É, —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π... –ø–æ–ø—Ä–æ–±—É–π —á—É—Ç—å –ø–æ–∑–∂–µ?"
            else:
                return "—á—Ç–æ-—Ç–æ —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º... –ø–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑?"
        except Exception:
            return "–æ–π, —á—Ç–æ-—Ç–æ —Å–≤—è–∑—å –±–∞—Ä–∞—Ö–ª–∏—Ç... –ø–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑?"

    async def aclose(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç HTTP –∫–ª–∏–µ–Ω—Ç"""
        if self._client is not None:
            await self._client.aclose()
            self._client = None