# app/llm_client.py
from __future__ import annotations
import asyncio
import sys
import traceback
from typing import List, Dict, Optional
import random
import re

import httpx
from openai import AsyncOpenAI, DefaultHttpxClient
from openai import AuthenticationError, PermissionDeniedError, APITimeoutError

from .config import settings
from .prompts import REFUSAL_STYLE

# –ë–∞–∑–æ–≤—ã–µ –¥–µ—Ñ–æ–ª—Ç—ã
DEFAULT_TEMPERATURE = 0.92
DEFAULT_MAX_TOKENS = 500  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —Ç–∞–π–º–∞—É—Ç–æ–≤
MAX_RESPONSE_LENGTH = 800  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ –≤ —Å–∏–º–≤–æ–ª–∞—Ö
SHORT_RESPONSE_LENGTH = 300

def _format_lists(text: str) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ —Å—Ç—Ä–æ–∫"""
    if not text:
        return text
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤
    # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤–∏–¥–∞ "1. —Ç–µ–∫—Å—Ç 2. —Ç–µ–∫—Å—Ç" –∏–ª–∏ "1) —Ç–µ–∫—Å—Ç 2) —Ç–µ–∫—Å—Ç"
    patterns = [
        (r'(\d+)\.\s+([^.!?]+?)(?=\s*\d+\.|$)', r'\1. \2'),
        (r'(\d+)\)\s+([^.!?]+?)(?=\s*\d+\)|$)', r'\1) \2'),
    ]
    
    for pattern, replacement in patterns:
        matches = list(re.finditer(pattern, text))
        if matches:
            # –°–æ–±–∏—Ä–∞–µ–º –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏
            parts = []
            last_end = 0
            
            for match in matches:
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –¥–æ —Å–ø–∏—Å–∫–∞
                if match.start() > last_end:
                    parts.append(text[last_end:match.start()].rstrip())
                
                # –î–æ–±–∞–≤–ª—è–µ–º —ç–ª–µ–º–µ–Ω—Ç —Å–ø–∏—Å–∫–∞ —Å –ø–µ—Ä–µ–Ω–æ—Å–æ–º
                item = match.group(1) + '. ' + match.group(2).strip()
                parts.append('\n' + item)
                last_end = match.end()
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞—Ç–æ–∫ —Ç–µ–∫—Å—Ç–∞
            if last_end < len(text):
                remaining = text[last_end:].lstrip()
                if remaining:
                    parts.append('\n' + remaining)
            
            text = ''.join(parts).strip()
            break
    
    # –¢–∞–∫–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ (- –∏–ª–∏ ‚Ä¢)
    text = re.sub(r'(?:^|\s)[-‚Ä¢]\s+', '\n‚Ä¢ ', text)
    
    return text

def _postprocess(text: str) -> str:
    """–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞"""
    if not text:
        return text

    # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å—ã
    t = text.strip()
    for prefix in ("–ê–ª–∏–Ω–∞:", "–ê–ª–∏–Ω–∞ ‚Äî", "–ê–ª–∏–Ω–∞ -"):
        if t.startswith(prefix):
            t = t[len(prefix):].strip()
            break

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–ø–∏—Å–∫–∏
    t = _format_lists(t)

    # –ó–∞–º–µ–Ω—è–µ–º Markdown –¥–ª—è Telegram
    t = re.sub(r'\*\*(.*?)\*\*', r'*\1*', t)
    
    # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
    t = re.sub(r'\n{3,}', '\n\n', t)

    return t.strip()

class LLMClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI API —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ ai-synthesizer)"""

    def __init__(self):
        self.api_key = settings.openai_api_key
        self.model = settings.openai_model
        self.use_proxy = settings.openai_use_proxy
        self.proxy_address = settings.openai_proxy_address
        self._client: Optional[AsyncOpenAI] = None

        if not self.api_key:
            raise RuntimeError("OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω –≤ .env —Ñ–∞–π–ª–µ")

    async def _get_client(self) -> AsyncOpenAI:
        """–õ–µ–Ω–∏–≤–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π –ø—Ä–æ–∫—Å–∏"""
        if self._client is None:
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ HTTP –∫–ª–∏–µ–Ω—Ç–∞ —Å –ø—Ä–æ–∫—Å–∏ (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ ai-synthesizer)
            http_client = None
            if self.use_proxy and self.proxy_address:
                http_client = DefaultHttpxClient(
                    proxy=self.proxy_address,
                    transport=httpx.HTTPTransport(local_address="0.0.0.0"),
                    timeout=httpx.Timeout(20.0, connect=5.0)
                )
                print(f"[LLM] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ–∫—Å–∏: {self.proxy_address}")
            else:
                http_client = DefaultHttpxClient(
                    timeout=httpx.Timeout(20.0, connect=5.0)
                )
                print("[LLM] –ü—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ OpenAI API")

            self._client = AsyncOpenAI(
                api_key=self.api_key,
                http_client=http_client,
                max_retries=2
            )
        
        return self._client

    def _openai_error_handler(func):
        """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ OpenAI (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ ai-synthesizer)"""
        async def wrapper(self, *args, **kwargs):
            try:
                return await func(self, *args, **kwargs)
            
            except PermissionDeniedError as error:
                if self.use_proxy:
                    error_message = "–æ–π, –ø—Ä–æ–±–ª–µ–º—ã —Å –ø—Ä–æ–∫—Å–∏... –ø—Ä–æ–≤–µ—Ä—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"
                else:
                    error_message = "–¥–æ—Å—Ç—É–ø –æ–≥—Ä–∞–Ω–∏—á–µ–Ω... –º–æ–∂–µ—Ç, –Ω—É–∂–µ–Ω –ø—Ä–æ–∫—Å–∏?"
                print(f"[LLM] Permission denied: {error}", file=sys.stderr)
                return error_message
                
            except AuthenticationError as error:
                print(f"[LLM] Authentication error: {error}", file=sys.stderr)
                return "–æ–π, –ø—Ä–æ–±–ª–µ–º—ã —Å –∫–ª—é—á–æ–º API... –ø—Ä–æ–≤–µ—Ä—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"
                
            except APITimeoutError as error:
                print(f"[LLM] Timeout error: {error}", file=sys.stderr)
                return "—Ö–º, —á—Ç–æ-—Ç–æ –¥–æ–ª–≥–æ –¥—É–º–∞—é... –º–æ–∂–µ—Ç, —Å–ø—Ä–æ—Å–∏—à—å –ø–æ–ø—Ä–æ—â–µ?"
                
            except Exception as error:
                print(f"[LLM] Unexpected error: {error}", file=sys.stderr)
                traceback.print_exc()
                return "–æ–π, —á—Ç–æ-—Ç–æ —Å–≤—è–∑—å –±–∞—Ä–∞—Ö–ª–∏—Ç... –ø–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑?"
        
        return wrapper

    async def _shorten_response(self, original_text: str) -> str:
        """–°–æ–∫—Ä–∞—â–∞–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å"""
        print(f"[LLM] –°–æ–∫—Ä–∞—â–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç ({len(original_text)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        messages = [
            {"role": "system", "content": "–¢—ã –ê–ª–∏–Ω–∞. –°–æ–∫—Ä–∞—Ç–∏ —Å–≤–æ–π –æ—Ç–≤–µ—Ç, –æ—Å—Ç–∞–≤–∏–≤ —Ç–æ–ª—å–∫–æ —Å–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ –∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ. –ú–∞–∫—Å–∏–º—É–º 5 –ø—É–Ω–∫—Ç–æ–≤ –¥–ª—è —Å–ø–∏—Å–∫–æ–≤. –°–æ—Ö—Ä–∞–Ω–∏ —Ç—ë–ø–ª—ã–π —Ç–æ–Ω."},
            {"role": "assistant", "content": original_text},
            {"role": "user", "content": "–≠—Ç–æ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ. –°–æ–∫—Ä–∞—Ç–∏ –¥–æ —Å–∞–º–æ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–≥–æ, –æ—Å—Ç–∞–≤—å –º–∞–∫—Å–∏–º—É–º 5 –ø—É–Ω–∫—Ç–æ–≤ –µ—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫."}
        ]
        
        try:
            shortened = await self._make_request(messages, temperature=0.7, max_tokens=400)
            print(f"[LLM] –û—Ç–≤–µ—Ç —Å–æ–∫—Ä–∞—â—ë–Ω –¥–æ {len(shortened)} —Å–∏–º–≤–æ–ª–æ–≤")
            return shortened
        except Exception as e:
            print(f"[LLM] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–∏: {e}")
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∫—Ä–∞—Ç–∏—Ç—å —á–µ—Ä–µ–∑ API, –æ–±—Ä–µ–∑–∞–µ–º –º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–∏
            lines = original_text.split('\n')
            if len(lines) > 7:
                # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ + –¥–æ–±–∞–≤–ª—è–µ–º —Ñ—Ä–∞–∑—É
                result = '\n'.join(lines[:5])
                result += "\n\n—Ö–æ—á–µ—à—å –µ—â—ë? –º–æ–≥—É —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –±–æ–ª—å—à–µ üíõ"
                return result
            return original_text[:MAX_RESPONSE_LENGTH] + "..."

    @_openai_error_handler
    async def _make_request(self, messages: List[Dict[str, str]], temperature: float, max_tokens: int) -> str:
        """–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI API"""
        client = await self._get_client()
        
        response = await client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            top_p=0.95,
            frequency_penalty=0.3,
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º finish_reason
        choice = response.choices[0]
        finish_reason = choice.finish_reason
        
        if finish_reason == "length":
            print(f"[LLM] –í–ù–ò–ú–ê–ù–ò–ï: –û—Ç–≤–µ—Ç –æ–±—Ä–µ–∑–∞–Ω –∏–∑-–∑–∞ –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ (max_tokens={max_tokens})")
        
        return choice.message.content or ""

    async def chat(
        self,
        messages: List[Dict[str, str]],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        *,
        verbosity: Optional[str] = None,
        safety: bool = False,
    ) -> str:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ OpenAI API —Å —É–º–Ω—ã–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –¥–ª–∏–Ω—ã"""
        
        temperature = float(temperature if temperature is not None else DEFAULT_TEMPERATURE)
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π max_tokens, –Ω–æ —Å —Ä–∞–∑—É–º–Ω—ã–º–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏
        if verbosity == "short":
            max_tokens = SHORT_RESPONSE_LENGTH
        elif verbosity == "long":
            # –î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ç–∞–π–º–∞—É—Ç–æ–≤
            max_tokens = MAX_RESPONSE_LENGTH  
        else:
            max_tokens = int(max_tokens if max_tokens is not None else DEFAULT_MAX_TOKENS)

        if safety:
            messages = [{"role": "system", "content": REFUSAL_STYLE}] + messages

        # –î–æ–±–∞–≤–ª—è–µ–º —É–∫–∞–∑–∞–Ω–∏–µ –ø—Ä–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–æ–≤
        last_user_msg = messages[-1].get("content", "").lower()
        if any(word in last_user_msg for word in ["—Ñ–∞–∫—Ç", "–ø—É–Ω–∫—Ç", "—Å–ø–∏—Å–æ–∫", "–ø—Ä–∏—á–∏–Ω", "—Å–ø–æ—Å–æ–±"]):
            # –ï—Å–ª–∏ –ø—Ä–æ—Å—è—Ç —Å–ø–∏—Å–æ–∫, —è–≤–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º
            messages.append({
                "role": "system", 
                "content": "–í–ê–ñ–ù–û: –î–∞–∂–µ –µ—Å–ª–∏ –ø—Ä–æ—Å—è—Ç –º–Ω–æ–≥–æ –ø—É–Ω–∫—Ç–æ–≤, –¥–∞–π –º–∞–∫—Å–∏–º—É–º 5 —Å–∞–º—ã—Ö –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã—Ö. –ö–∞–∂–¥—ã–π –ø—É–Ω–∫—Ç —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏. –í –∫–æ–Ω—Ü–µ –º–æ–∂–µ—à—å —Å–ø—Ä–æ—Å–∏—Ç—å, —Ö–æ—á–µ—Ç –ª–∏ —á–µ–ª–æ–≤–µ–∫ –µ—â—ë."
            })
        else:
            messages.append({
                "role": "system", 
                "content": "–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É. –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –ø–æ–ª—É—á–∞–µ—Ç—Å—è –¥–ª–∏–Ω–Ω—ã–º, —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á—å—Å—è –Ω–∞ –≥–ª–∞–≤–Ω–æ–º."
            })

        # –û—Ç–ª–∞–¥–æ—á–Ω—ã–π –≤—ã–≤–æ–¥
        print(f"[LLM] –ó–∞–ø—Ä–æ—Å –∫ {self.model} —Å max_tokens={max_tokens}, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞={temperature}")
        
        try:
            txt = await self._make_request(messages, temperature, max_tokens)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞
            if len(txt) > MAX_RESPONSE_LENGTH:
                txt = await self._shorten_response(txt)
            
            # –û—Ç–ª–∞–¥–∫–∞ –¥–ª–∏–Ω—ã –æ—Ç–≤–µ—Ç–∞
            print(f"[LLM] –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç: {len(txt)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            return _postprocess(txt)
            
        except Exception as e:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —É–∂–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–µ
            print(f"[LLM] –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: {e}", file=sys.stderr)
            return "—á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫... –ø–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑?"

    async def aclose(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç OpenAI –∫–ª–∏–µ–Ω—Ç"""
        if self._client is not None:
            await self._client.close()
            self._client = None